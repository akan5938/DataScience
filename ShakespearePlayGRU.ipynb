{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare Play Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.utils as ku \n",
    "\n",
    "# set seeds for reproducability\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "tf.random.set_seed(2)\n",
    "seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_df = pd.read_csv('./archive/Shakespeare_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act i',\n",
       " 'scene i london the palace',\n",
       " 'enter king henry lord john of lancaster the earl of westmoreland sir walter blunt and others',\n",
       " 'so shaken as we are so wan with care',\n",
       " 'find we a time for frighted peace to pant',\n",
       " 'and breathe shortwinded accents of new broils',\n",
       " 'to be commenced in strands afar remote',\n",
       " 'no more the thirsty entrance of this soil',\n",
       " 'shall daub her lips with her own childrens blood',\n",
       " 'nor more shall trenching war channel her fields']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lines = [h for h in play_df.PlayerLine]\n",
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt \n",
    "\n",
    "corpus = [clean_text(x) for x in all_lines]\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[523, 4],\n",
       " [142, 4],\n",
       " [142, 4, 339],\n",
       " [142, 4, 339, 1],\n",
       " [142, 4, 339, 1, 670],\n",
       " [53, 41],\n",
       " [53, 41, 84],\n",
       " [53, 41, 84, 29],\n",
       " [53, 41, 84, 29, 124],\n",
       " [53, 41, 84, 29, 124, 3]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    corpus = corpus[:7000]\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "inp_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45584, 33), (45584, 6543))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
    "predictors.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 33, 10)            65430     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 512)               1071104   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6543)              3356559   \n",
      "=================================================================\n",
      "Total params: 4,493,093\n",
      "Trainable params: 4,493,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1425/1425 - 549s - loss: 6.8415\n",
      "Epoch 2/20\n",
      "1425/1425 - 495s - loss: 6.5198\n",
      "Epoch 3/20\n",
      "1425/1425 - 477s - loss: 6.3824\n",
      "Epoch 4/20\n",
      "1425/1425 - 315s - loss: 6.2359\n",
      "Epoch 5/20\n",
      "1425/1425 - 287s - loss: 6.0600\n",
      "Epoch 6/20\n",
      "1425/1425 - 295s - loss: 5.8758\n",
      "Epoch 7/20\n",
      "1425/1425 - 256s - loss: 5.6699\n",
      "Epoch 8/20\n",
      "1425/1425 - 309s - loss: 5.4338\n",
      "Epoch 9/20\n",
      "1425/1425 - 321s - loss: 5.1848\n",
      "Epoch 10/20\n",
      "1425/1425 - 236s - loss: 4.9108\n",
      "Epoch 11/20\n",
      "1425/1425 - 243s - loss: 4.6376\n",
      "Epoch 12/20\n",
      "1425/1425 - 254s - loss: 4.3579\n",
      "Epoch 13/20\n",
      "1425/1425 - 244s - loss: 4.1049\n",
      "Epoch 14/20\n",
      "1425/1425 - 226s - loss: 3.8681\n",
      "Epoch 15/20\n",
      "1425/1425 - 214s - loss: 3.6492\n",
      "Epoch 16/20\n",
      "1425/1425 - 199s - loss: 3.4520\n",
      "Epoch 17/20\n",
      "1425/1425 - 210s - loss: 3.2831\n",
      "Epoch 18/20\n",
      "1425/1425 - 219s - loss: 3.1145\n",
      "Epoch 19/20\n",
      "1425/1425 - 228s - loss: 2.9807\n",
      "Epoch 20/20\n",
      "1425/1425 - 196s - loss: 2.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x68d5c3b90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-d8873b000447>:5: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "1.  Julius If I Have Dealt Ill Make Him If I Do Not If I Am My Blood If I Can Not\n",
      "2.  Thou Art The Most Mortimer Of The Commons Gates Out Of England And The Sea Of A Coats Then Within Two\n",
      "3.  King Is Much Myself And Never Evident Are Me You I Know Not Be Old Out Of The Living Burly Of The\n",
      "4.  Death Of The Days Of The Land Month At Me And The Fifth Then Then And Their Half And C It Thunders\n",
      "5.  The Princess Of The Day Of Hosts He Fought Of The Rest Of The Ladder Of The Gallows Stars And A Feast\n",
      "6.  Thanos Me I Am Withered As Back I Am Purge To A Cat Of My Own Lord Of London It And\n"
     ]
    }
   ],
   "source": [
    "print (\"1. \",generate_text(\"Julius\", 20, model, max_sequence_len))\n",
    "print (\"2. \",generate_text(\"Thou\", 20, model, max_sequence_len))\n",
    "print (\"3. \",generate_text(\"King is\", 20, model, max_sequence_len))\n",
    "print (\"4. \",generate_text(\"Death of\", 20, model, max_sequence_len))\n",
    "print (\"5. \",generate_text(\"The Princess\", 20, model, max_sequence_len))\n",
    "print (\"6. \",generate_text(\"Thanos\", 20, model, max_sequence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
